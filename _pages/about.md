---
layout: about
title: about
permalink: /
subtitle: MSc Artificial Intelligence · University of Edinburgh

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false
  more_info: >
    <p>University of Edinburgh</p>
    <p>Edinburgh, UK</p>

nav: true
nav_order: 1

selected_papers: true
social: true

announcements:
  enabled: true
  scrollable: true
  limit: 5

latest_posts:
  enabled: true
  scrollable: true
  limit: 3
---

I am an MSc Artificial Intelligence student at the University of Edinburgh. Previously, I was a predoctoral researcher at the Indian Institute of Science (Bengaluru), where I worked with <a href="https://www.punitrathore.com/" target="_blank" rel="noopener">Prof. Punit Rathore</a> on projects involving graph neural networks and computer vision.

My current interests include mechanistic interpretability in large language models and AI safety. I’m especially interested in model behavior under **distribution shift** and **adversarial conditions**—settings where inputs are out-of-domain or intentionally designed to challenge the system. These conditions often reveal capabilities and failure modes that do not appear in standard evaluations, and they help us understand how reliably models operate in real-world applications when deployed to assist people.

For my master’s thesis, I am developing a benchmark for **self-evolving LLM agents** that must integrate web search with coding to accomplish end-to-end, real-world tasks. The benchmark evaluates not only final accuracy, but also iterative improvement, tool creation and reuse, and trustworthy use of external information through automated testing and rubric-based evaluation.

### Research keywords
Mechanistic interpretability · AI safety · LLM agents · Distribution shift · Adversarial robustness · Graph neural networks
