---
layout: about
title: about
permalink: /
subtitle: MSc Artificial Intelligence · University of Edinburgh

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false
  more_info: >
    <p>London, UK</p>

nav: true
nav_order: 1

selected_papers: true
social: true

announcements:
  enabled: true
  scrollable: true
  limit: 5

latest_posts:
  enabled: false #changed to false
  scrollable: false #changed to false
  limit: 3
---

I am a master's student at the University of Edinburgh, being supervised by <a href="https://scholar.google.com/citations?user=zLDAY8QAAAAJ&hl=en" target="_blank" rel="noopener">Prof. Jeff Pan</a>. Previously, I was a predoctoral researcher at the Indian Institute of Science (Bengaluru), where I worked with <a href="https://www.vistalabiisc.com/P_portfolio" target="_blank" rel="noopener">Prof. Punit Rathore</a> on projects related to Graph Neural Networks and Computer Vision. I also had the chance to work with <a href="https://scholar.google.com/citations?user=Gu8FjdwAAAAJ&hl=en" target="_blank" rel="noopener">Prof. Sundeep Chepuri</a> on one of these projects.

My current interests include mechanistic interpretability in LLMs and AI safety. I’m interested in understanding how the model behaves under distribution shifts and adversarial conditions, such as when inputs are out-of-domain or intentionally designed to challenge the system. These situations often reveal capabilities and failure modes that don't show up in standard evaluations, helping us understand how reliably these models operate in real-world applications when deployed to assist people.

For my master’s thesis, I’m developing a benchmark to assess **self-evolving LLM agents** that integrate web search and coding tools within a unified workflow. The benchmark aims to measure the synergy of these capabilities by testing end-to-end tasks in which an agent must search for information, validate and interpret it, and then write robust code to automate subtasks or create reusable components for longer pipelines. Agents will be evaluated based on final correctness, adaptability, iterative planning, and tool development.

### Research keywords
Mechanistic interpretability · AI safety · LLM agents · Graph neural networks
